/*
LMUL=8 RVV SGEMM "AUTOGENERATED-STYLE" KERNEL (FULL, NO MISSING PARTS)
Target:
  LMUL=8
  M main = 64  (VLEN=256b, FP32 => 8 lanes per m1, 64 lanes per m8)
  N main = 2   (IMPORTANT: LMUL=8 cannot keep 8 accumulators live)
  cpu = 'zvl256b'
  param_precision = float

Why N=2 (not 8):
  Each vfloat32m8_t uses 8 vector registers. 8 accumulators (N=8) would need
  ~64 vector registers, but RVV has 32. So LMUL=8 kernels must use small N
  (typically 1 or 2).

Memory layout assumption (OpenBLAS-style packed panels):
  - A packed as [k][MB] contiguous: A[(m_top*K) + k*MB + r]
  - B packed as [k][NB] contiguous: B[(n_top*K) + k*NB + c]
  - C column-major with ldc: C[(n_top+col)*ldc + (m_top+row)]

Interface:
  int CNAME(BLASLONG M, BLASLONG N, BLASLONG K,
            FLOAT alpha, FLOAT* A, FLOAT* B, FLOAT* C, BLASLONG ldc);
*/

#include <riscv_vector.h>
#include <stddef.h>

typedef long  BLASLONG;
typedef float FLOAT;

#ifndef CNAME
#define CNAME sgemm_kernel_64x2_zvl256b_lmul8
#endif

static inline void kern2_f32m8(BLASLONG K,
                              const FLOAT *Ap, const FLOAT *Bp,
                              FLOAT *Cp, BLASLONG ldc,
                              FLOAT alpha, size_t gvl, BLASLONG MB)
{
    FLOAT b0 = Bp[0], b1 = Bp[1];
    Bp += 2;

    vfloat32m8_t av = __riscv_vle32_v_f32m8(Ap, gvl);
    Ap += MB;

    vfloat32m8_t r0 = __riscv_vfmul_vf_f32m8(av, b0, gvl);
    vfloat32m8_t r1 = __riscv_vfmul_vf_f32m8(av, b1, gvl);

    for (BLASLONG k = 1; k < K; k++) {
        b0 = Bp[0]; b1 = Bp[1];
        Bp += 2;

        av = __riscv_vle32_v_f32m8(Ap, gvl);
        Ap += MB;

        r0 = __riscv_vfmacc_vf_f32m8(r0, b0, av, gvl);
        r1 = __riscv_vfmacc_vf_f32m8(r1, b1, av, gvl);
    }

    // Update/store column 0
    {
        vfloat32m8_t c0 = __riscv_vle32_v_f32m8(Cp + 0*ldc, gvl);
        c0 = __riscv_vfmacc_vf_f32m8(c0, alpha, r0, gvl);
        __riscv_vse32_v_f32m8(Cp + 0*ldc, c0, gvl);
    }
    // Update/store column 1
    {
        vfloat32m8_t c1 = __riscv_vle32_v_f32m8(Cp + 1*ldc, gvl);
        c1 = __riscv_vfmacc_vf_f32m8(c1, alpha, r1, gvl);
        __riscv_vse32_v_f32m8(Cp + 1*ldc, c1, gvl);
    }
}

static inline void kern1_f32m8(BLASLONG K,
                              const FLOAT *Ap, const FLOAT *Bp,
                              FLOAT *Cp, BLASLONG ldc,
                              FLOAT alpha, size_t gvl, BLASLONG MB)
{
    FLOAT b0 = Bp[0];
    Bp += 1;

    vfloat32m8_t av = __riscv_vle32_v_f32m8(Ap, gvl);
    Ap += MB;

    vfloat32m8_t r0 = __riscv_vfmul_vf_f32m8(av, b0, gvl);

    for (BLASLONG k = 1; k < K; k++) {
        b0 = Bp[0];
        Bp += 1;

        av = __riscv_vle32_v_f32m8(Ap, gvl);
        Ap += MB;

        r0 = __riscv_vfmacc_vf_f32m8(r0, b0, av, gvl);
    }

    vfloat32m8_t c0 = __riscv_vle32_v_f32m8(Cp + 0*ldc, gvl);
    c0 = __riscv_vfmacc_vf_f32m8(c0, alpha, r0, gvl);
    __riscv_vse32_v_f32m8(Cp + 0*ldc, c0, gvl);
}

// Scalar tails for M=2 or M=1
static inline void scalar_tail_2(BLASLONG NB, BLASLONG K,
                                const FLOAT *Ap, const FLOAT *Bp,
                                FLOAT *Cp, BLASLONG ldc,
                                FLOAT alpha)
{
    for (BLASLONG j = 0; j < NB; j++) {
        FLOAT r0 = 0.0f, r1 = 0.0f;
        const FLOAT *a = Ap;
        const FLOAT *b = Bp + j;
        for (BLASLONG k = 0; k < K; k++) {
            FLOAT a0 = a[0];
            FLOAT a1 = a[1];
            FLOAT bj = b[0];
            r0 += a0 * bj;
            r1 += a1 * bj;
            a += 2;
            b += NB;
        }
        Cp[j*ldc + 0] += alpha * r0;
        Cp[j*ldc + 1] += alpha * r1;
    }
}

static inline void scalar_tail_1(BLASLONG NB, BLASLONG K,
                                const FLOAT *Ap, const FLOAT *Bp,
                                FLOAT *Cp, BLASLONG ldc,
                                FLOAT alpha)
{
    for (BLASLONG j = 0; j < NB; j++) {
        FLOAT r0 = 0.0f;
        const FLOAT *a = Ap;
        const FLOAT *b = Bp + j;
        for (BLASLONG k = 0; k < K; k++) {
            r0 += a[0] * b[0];
            a += 1;
            b += NB;
        }
        Cp[j*ldc + 0] += alpha * r0;
    }
}

int CNAME(BLASLONG M, BLASLONG N, BLASLONG K,
          FLOAT alpha, FLOAT *A, FLOAT *B, FLOAT *C, BLASLONG ldc)
{
    if (M <= 0 || N <= 0) return 0;
    if (K <= 0) return 0;

    BLASLONG m_top, n_top = 0;

    // Main: NB=2
    for (BLASLONG jblk = 0; jblk < (N / 2); jblk++) {
        m_top = 0;

        for (BLASLONG iblk = 0; iblk < (M / 64); iblk++) {
            const FLOAT *Ap = A + (m_top * K);
            const FLOAT *Bp = B + (n_top * K);
            FLOAT *Cp = C + (n_top * ldc + m_top);

            size_t gvl = __riscv_vsetvl_e32m8(64);
            kern2_f32m8(K, Ap, Bp, Cp, ldc, alpha, gvl, 64);
            m_top += 64;
        }

        if (M & 32) {
            const FLOAT *Ap = A + (m_top * K);
            const FLOAT *Bp = B + (n_top * K);
            FLOAT *Cp = C + (n_top * ldc + m_top);
            size_t gvl = __riscv_vsetvl_e32m8(32);
            kern2_f32m8(K, Ap, Bp, Cp, ldc, alpha, gvl, 32);
            m_top += 32;
        }
        if (M & 16) {
            const FLOAT *Ap = A + (m_top * K);
            const FLOAT *Bp = B + (n_top * K);
            FLOAT *Cp = C + (n_top * ldc + m_top);
            size_t gvl = __riscv_vsetvl_e32m8(16);
            kern2_f32m8(K, Ap, Bp, Cp, ldc, alpha, gvl, 16);
            m_top += 16;
        }
        if (M & 8) {
            const FLOAT *Ap = A + (m_top * K);
            const FLOAT *Bp = B + (n_top * K);
            FLOAT *Cp = C + (n_top * ldc + m_top);
            size_t gvl = __riscv_vsetvl_e32m8(8);
            kern2_f32m8(K, Ap, Bp, Cp, ldc, alpha, gvl, 8);
            m_top += 8;
        }
        if (M & 4) {
            const FLOAT *Ap = A + (m_top * K);
            const FLOAT *Bp = B + (n_top * K);
            FLOAT *Cp = C + (n_top * ldc + m_top);
            size_t gvl = __riscv_vsetvl_e32m8(4);
            kern2_f32m8(K, Ap, Bp, Cp, ldc, alpha, gvl, 4);
            m_top += 4;
        }
        if (M & 2) {
            const FLOAT *Ap = A + (m_top * K);
            const FLOAT *Bp = B + (n_top * K);
            FLOAT *Cp = C + (n_top * ldc + m_top);
            scalar_tail_2(2, K, Ap, Bp, Cp, ldc, alpha);
            m_top += 2;
        }
        if (M & 1) {
            const FLOAT *Ap = A + (m_top * K);
            const FLOAT *Bp = B + (n_top * K);
            FLOAT *Cp = C + (n_top * ldc + m_top);
            scalar_tail_1(2, K, Ap, Bp, Cp, ldc, alpha);
            m_top += 1;
        }

        n_top += 2;
    }

    // N tail: NB=1
    if (N & 1) {
        m_top = 0;

        for (BLASLONG iblk = 0; iblk < (M / 64); iblk++) {
            const FLOAT *Ap = A + (m_top * K);
            const FLOAT *Bp = B + (n_top * K);
            FLOAT *Cp = C + (n_top * ldc + m_top);

            size_t gvl = __riscv_vsetvl_e32m8(64);
            kern1_f32m8(K, Ap, Bp, Cp, ldc, alpha, gvl, 64);
            m_top += 64;
        }

        if (M & 32) {
            const FLOAT *Ap = A + (m_top * K);
            const FLOAT *Bp = B + (n_top * K);
            FLOAT *Cp = C + (n_top * ldc + m_top);
            size_t gvl = __riscv_vsetvl_e32m8(32);
            kern1_f32m8(K, Ap, Bp, Cp, ldc, alpha, gvl, 32);
            m_top += 32;
        }
        if (M & 16) {
            const FLOAT *Ap = A + (m_top * K);
            const FLOAT *Bp = B + (n_top * K);
            FLOAT *Cp = C + (n_top * ldc + m_top);
            size_t gvl = __riscv_vsetvl_e32m8(16);
            kern1_f32m8(K, Ap, Bp, Cp, ldc, alpha, gvl, 16);
            m_top += 16;
        }
        if (M & 8) {
            const FLOAT *Ap = A + (m_top * K);
            const FLOAT *Bp = B + (n_top * K);
            FLOAT *Cp = C + (n_top * ldc + m_top);
            size_t gvl = __riscv_vsetvl_e32m8(8);
            kern1_f32m8(K, Ap, Bp, Cp, ldc, alpha, gvl, 8);
            m_top += 8;
        }
        if (M & 4) {
            const FLOAT *Ap = A + (m_top * K);
            const FLOAT *Bp = B + (n_top * K);
            FLOAT *Cp = C + (n_top * ldc + m_top);
            size_t gvl = __riscv_vsetvl_e32m8(4);
            kern1_f32m8(K, Ap, Bp, Cp, ldc, alpha, gvl, 4);
            m_top += 4;
        }
        if (M & 2) {
            const FLOAT *Ap = A + (m_top * K);
            const FLOAT *Bp = B + (n_top * K);
            FLOAT *Cp = C + (n_top * ldc + m_top);
            scalar_tail_2(1, K, Ap, Bp, Cp, ldc, alpha);
            m_top += 2;
        }
        if (M & 1) {
            const FLOAT *Ap = A + (m_top * K);
            const FLOAT *Bp = B + (n_top * K);
            FLOAT *Cp = C + (n_top * ldc + m_top);
            scalar_tail_1(1, K, Ap, Bp, Cp, ldc, alpha);
            m_top += 1;
        }

        n_top += 1;
    }

    return 0;
}

/*
Compile example:
  gcc -O3 -march=rv64gcv_zvl256b -mabi=lp64d -std=c11 -Wall -Wextra sgemm_kernel_64x2_zvl256b_lmul8.c -c
*/
